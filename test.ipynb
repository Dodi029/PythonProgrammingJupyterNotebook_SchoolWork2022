{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6e8807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rm\n",
    "import math\n",
    "import os\n",
    "\n",
    "dataframe = pd.read_csv('/Users/doyoung/학교/Python_Programming_JupyterNotebook/데이터/iris.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ae907cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_array = []\n",
    "y_dataframe = pd.DataFrame(dataframe['class'])\n",
    "for i in range(0, len(dataframe)):\n",
    "    x_list = dataframe.iloc[i].tolist()\n",
    "    x_data_array.append(x_list[0:4])\n",
    "    x_dataframe = pd.DataFrame(x_data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "44fd79f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(x_dataframe, y_dataframe, train_rate = 0.75, random = False, random_seed = None):\n",
    "    index = list(range(len(x_dataframe)))\n",
    "    train_size = round(len(index)*train_rate)\n",
    "\n",
    "    if(random == True):\n",
    "        if(random_seed != None):\n",
    "            rm.seed(random_seed)\n",
    "        rm.shuffle(index)\n",
    "\n",
    "    train_index = index[0:train_size]\n",
    "    test_index = index[train_size:]\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    Y_train = []\n",
    "    Y_test = []\n",
    "        \n",
    "    for index in train_index:\n",
    "        X_train.append(x_dataframe.iloc[index].tolist())\n",
    "        Y_train.append(y_dataframe.iloc[index].tolist())\n",
    "    for index in test_index:\n",
    "        X_test.append(x_dataframe.iloc[index].tolist())\n",
    "        Y_test.append(y_dataframe.iloc[index].tolist())\n",
    "\n",
    "    return X_train, X_test, sum(Y_train, []), sum(Y_test, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9cdc2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.fit_model = list()\n",
    "    \n",
    "    def Euclidean_Distance(self, sample_A, sample_B):\n",
    "        len_array = np.array(sample_A) - np.array(sample_B)\n",
    "        length = math.sqrt(np.sum(len_array**2))\n",
    "        return length\n",
    "    \n",
    "    def Manhattan_Distance(self, sample_A, sample_B):\n",
    "        len_array = np.array(sample_A) - np.array(sample_B)\n",
    "        length = np.sum(np.abs(len_array))\n",
    "        return length\n",
    "    \n",
    "    def Neighbor(self, X, test_sample):\n",
    "        length_list = list()\n",
    "        for x_data in X:\n",
    "            length_list.append(self.Euclidean_Distance(x_data, test_sample))\n",
    "        sort_index = np.argsort(length_list)\n",
    "        return sort_index[0:self.k]\n",
    "    \n",
    "    def Fit(self, X, Y, test_X):\n",
    "        fit_list = []\n",
    "        for test_sample in test_X:\n",
    "            neighbor = self.Neighbor(X, test_sample)\n",
    "            classfication_list = []\n",
    "            for index in neighbor:\n",
    "                classfication_list.append(Y[index])\n",
    "            overlap_count = {}\n",
    "            for cf in classfication_list:\n",
    "                try: overlap_count[cf] += 1\n",
    "                except: overlap_count[cf] = 1\n",
    "            fit_list.append(max(overlap_count, key = overlap_count.get))\n",
    "        self.fit_model = fit_list\n",
    "        #return self.fit_model\n",
    "        model=list(map(float,self.fit_model))\n",
    "        new=0\n",
    "        for i in rnage(0, self.k):\n",
    "            new = new + model[i]\n",
    "        new = new/self.k\n",
    "        return new\n",
    "    \n",
    "    def Predict(self, test_Y):\n",
    "        match_count = 0\n",
    "        for i in range(0, len(test_Y)):\n",
    "            if self.fit_model[i] == test_Y[i]:\n",
    "                match_count += 1\n",
    "        return match_count/len(test_Y)\n",
    "    \n",
    "    def Confusion_Matrix(self, test_Y, dataframe, class_value):\n",
    "        class_list = list(set(dataframe[class_value]))\n",
    "        identity_matrix = [[0 for j in range(len(class_list))] for i in range(len(class_list))]\n",
    "        confusion_matrix = pd.DataFrame(identity_matrix, index=class_list, columns=class_list)\n",
    "        for i in range(0, len(test_Y)):\n",
    "            confusion_matrix[self.fit_model[i]][test_Y[i]] += 1\n",
    "        return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8047112f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Iris-setosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m Train_X, Test_X, Train_Y, Test_Y \u001b[38;5;241m=\u001b[39m SplitData(x_dataframe, y_dataframe, \u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m KNN(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTest_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m predict_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mPredict(Test_Y)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m정확도 : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(predict_model \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36mKNN.Fit\u001b[0;34m(self, X, Y, test_X)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_model \u001b[38;5;241m=\u001b[39m fit_list\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#return self.fit_model\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m new\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m rnage(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk):\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Iris-setosa'"
     ]
    }
   ],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = SplitData(x_dataframe, y_dataframe, 0.75, True)\n",
    "model = KNN(5)\n",
    "model.Fit(Train_X, Train_Y, Test_X)\n",
    "predict_model = model.Predict(Test_Y)\n",
    "print(\"정확도 : {}%\\n\".format(predict_model * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95c220f",
   "metadata": {},
   "source": [
    "# MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ac3783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "f = open('/Users/doyoung/학교/Python_Programming_JupyterNotebook/데이터/ToyotaCorolla.txt', 'r', encoding = 'utf-8')\n",
    "data = f.readlines()\n",
    "f.close()\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in range(1, len(data)):\n",
    "    data_list.append(data[i].split('\\t'))\n",
    "\n",
    "price_data_list = []\n",
    "age_data_list = []\n",
    "km_data_list = []\n",
    "cc_data_list = []\n",
    "door_data_list = []\n",
    "weight_data_list = []\n",
    "x_record = []\n",
    "\n",
    "for n in data_list:\n",
    "    price_data_list.append(int(n[1]))\n",
    "    age_data_list.append(int(n[2]))\n",
    "    km_data_list.append(int(n[3]))\n",
    "    cc_data_list.append(int(n[4]))\n",
    "    door_data_list.append(int(n[5]))\n",
    "    weight_data_list.append(int(n[6]))\n",
    "    x_record.append([int(n[2]), int(n[3]), int(n[4]), int(n[5]), int(n[6])])\n",
    "    \n",
    "x_array_data = np.array(x_record)\n",
    "y_array_data = np.array(price_data_list)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c9d2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(x_array_data, y_array_data, test_rate = 0.75, random = False, random_seed = None):\n",
    "    index = np.array(range(len(x_array_data)))\n",
    "    test_size = round(len(x_array_data)*test_rate)\n",
    "\n",
    "    if(random == True):\n",
    "        if(random_seed != None):\n",
    "            random_generator = np.random.RandomState(seed=random_seed)\n",
    "            random_generator.shuffle(index)\n",
    "\n",
    "        else:\n",
    "            np.random.shuffle(index)\n",
    "\n",
    "        train_index = index[0:test_size]\n",
    "        test_index = index[test_size:]\n",
    "\n",
    "        X_train = x_array_data[train_index,:]\n",
    "        X_test = x_array_data[test_index,:]\n",
    "        Y_train = y_array_data[train_index]\n",
    "        Y_test = y_array_data[test_index]\n",
    "\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    else:\n",
    "        train_index = index[0:test_size]\n",
    "        test_index = index[test_size:]\n",
    "\n",
    "        X_train = x_array_data[train_index,:]\n",
    "        X_test = x_array_data[test_index,:]\n",
    "        Y_train = y_array_data[train_index]\n",
    "        Y_test = y_array_data[test_index]\n",
    "        \n",
    "        return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac598c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLR:\n",
    "    def __init__(self):\n",
    "        self.coef = None\n",
    "        \n",
    "    def InterceptAdd(self,X):\n",
    "        ones = np.ones(len(X)).reshape(-1,1)\n",
    "        result = np.concatenate([X,ones],axis=1)\n",
    "        return result\n",
    "    \n",
    "    def Fit(self,X,Y,intercept_add=False):\n",
    "        if(intercept_add == True):\n",
    "            new_X = self.InterceptAdd(X)\n",
    "            self.coef = np.linalg.inv(new_X.transpose()@new_X)@new_X.transpose()@Y\n",
    "            return self.coef\n",
    "        else:\n",
    "            self.coef = np.linalg.inv(X.transpose()@X)@X.transpose()@Y\n",
    "            return self.coef\n",
    "        \n",
    "    def Predict(self,X,intercept_add=False):\n",
    "        if(intercept_add==True):\n",
    "            new_X = self.InterceptAdd(X)\n",
    "            predict_value = new_X@self.coef\n",
    "            return predict_value\n",
    "        else:\n",
    "            predict_value = X@self.coef\n",
    "            return predict_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aed74ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class METRIX:\n",
    "    def __init__(self):\n",
    "        self.mse_result=0\n",
    "        self.mape_result=0\n",
    "        \n",
    "    def Mse(self,true_y,pred_y):\n",
    "        residual = true_y - pred_y\n",
    "        square_residual = residual*residual\n",
    "        self.mse_result =  np.mean(square_residual)\n",
    "        return self.mse_result\n",
    "        \n",
    "    def Mape(self,true_y,pred_y):\n",
    "        residual = true_y - pred_y\n",
    "        temp = np.abs(residual)/np.abs(true_y)*100 \n",
    "        self.mape_result = np.mean(temp)\n",
    "        return self.mape_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1296a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 1474274.92\n",
      "MAPE : 11.92%\n"
     ]
    }
   ],
   "source": [
    "x_tr_array = SplitData(x_array_data, y_array_data)[0]\n",
    "x_ts_array = SplitData(x_array_data, y_array_data)[1]\n",
    "y_tr_array = SplitData(x_array_data, y_array_data)[2]\n",
    "y_ts_array = SplitData(x_array_data, y_array_data)[3]\n",
    "\n",
    "model = MLR()\n",
    "model.Fit(x_tr_array, y_tr_array, True)\n",
    "y_predict = model.Predict(x_ts_array, True)\n",
    "test = METRIX()\n",
    "print(\"MSE : {:.2f}\".format(test.Mse(y_ts_array, y_predict)))\n",
    "print(\"MAPE : {:.2f}%\".format(test.Mape(y_ts_array, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480047fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
