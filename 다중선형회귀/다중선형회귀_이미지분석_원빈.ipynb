{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b613425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def imageList(image_data_path):\n",
    "    open_image = Image.open(image_data_path)\n",
    "    image_array = np.asarray(open_image)\n",
    "    x_list = sum(image_array.tolist(),[])\n",
    "    return x_list\n",
    "\n",
    "train_data_path_list = []\n",
    "test_data_path_list = []\n",
    "\n",
    "train_data_path_list_0 = glob('./mnist_png/training/0/*.png')\n",
    "train_data_path_list_1 = glob('./mnist_png/training/1/*.png')\n",
    "train_data_path_list_2 = glob('./mnist_png/training/2/*.png')\n",
    "train_data_path_list_3 = glob('./mnist_png/training/3/*.png')\n",
    "train_data_path_list_4 = glob('./mnist_png/training/4/*.png')\n",
    "train_data_path_list_5 = glob('./mnist_png/training/5/*.png')\n",
    "train_data_path_list_6 = glob('./mnist_png/training/6/*.png')\n",
    "train_data_path_list_7 = glob('./mnist_png/training/7/*.png')\n",
    "train_data_path_list_8 = glob('./mnist_png/training/8/*.png')\n",
    "train_data_path_list_9 = glob('./mnist_png/training/9/*.png')\n",
    "\n",
    "test_data_path_list_0 = glob('./mnist_png/testing/0/*.png')\n",
    "test_data_path_list_1 = glob('./mnist_png/testing/1/*.png')\n",
    "test_data_path_list_2 = glob('./mnist_png/testing/2/*.png')\n",
    "test_data_path_list_3 = glob('./mnist_png/testing/3/*.png')\n",
    "test_data_path_list_4 = glob('./mnist_png/testing/4/*.png')\n",
    "test_data_path_list_5 = glob('./mnist_png/testing/5/*.png')\n",
    "test_data_path_list_6 = glob('./mnist_png/testing/6/*.png')\n",
    "test_data_path_list_7 = glob('./mnist_png/testing/7/*.png')\n",
    "test_data_path_list_8 = glob('./mnist_png/testing/8/*.png')\n",
    "test_data_path_list_9 = glob('./mnist_png/testing/9/*.png')\n",
    "\n",
    "train_data_path_list.append(train_data_path_list_0)\n",
    "train_data_path_list.append(train_data_path_list_1)\n",
    "train_data_path_list.append(train_data_path_list_2)\n",
    "train_data_path_list.append(train_data_path_list_3)\n",
    "train_data_path_list.append(train_data_path_list_4)\n",
    "train_data_path_list.append(train_data_path_list_5)\n",
    "train_data_path_list.append(train_data_path_list_6)\n",
    "train_data_path_list.append(train_data_path_list_7)\n",
    "train_data_path_list.append(train_data_path_list_8)\n",
    "train_data_path_list.append(train_data_path_list_9)\n",
    "\n",
    "test_data_path_list.append(test_data_path_list_0)\n",
    "test_data_path_list.append(test_data_path_list_1)\n",
    "test_data_path_list.append(test_data_path_list_2)\n",
    "test_data_path_list.append(test_data_path_list_3)\n",
    "test_data_path_list.append(test_data_path_list_4)\n",
    "test_data_path_list.append(test_data_path_list_5)\n",
    "test_data_path_list.append(test_data_path_list_6)\n",
    "test_data_path_list.append(test_data_path_list_7)\n",
    "test_data_path_list.append(test_data_path_list_8)\n",
    "test_data_path_list.append(test_data_path_list_9)\n",
    "\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "x_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, len(train_data_path_list)):\n",
    "    for j in range(0, len(train_data_path_list[i])):\n",
    "        x_train_list.append(imageList(train_data_path_list[i][j]))\n",
    "        y_train_list.append(i)\n",
    "        \n",
    "for i in range(0, len(test_data_path_list)):\n",
    "    for j in range(0, len(test_data_path_list[i])):\n",
    "        x_test_list.append(imageList(test_data_path_list[i][j]))\n",
    "        y_test_list.append(i)\n",
    "        \n",
    "x_train_array = np.array(x_train_list)\n",
    "y_train_array = np.array(y_train_list)\n",
    "x_test_array = np.array(x_test_list)\n",
    "y_test_array = np.array(y_test_list)\n",
    "\n",
    "class MLR:\n",
    "    def __init__(self):\n",
    "        self.coef = None\n",
    "        \n",
    "    def InterceptAdd(self,X): # -> intercept Option 함수로 y 절편을 포함할지 아닐지 선택하는 함수 (X에 마지막 요소에 1을 추가하면 y 절편이 행렬곱으로 계산)\n",
    "        ones = np.ones(len(X)).reshape(-1,1) # np.ones() : 괄호안에 있는 길이만큼 요소가 1인 단위 행렬 제작\n",
    "        # np.reshape(a,b,..) : a행 b열로 변환하거나 다차원 행렬로 변환, a = -1이면 열(b) 값에 따라 알아서 행렬로 변환\n",
    "        # -> 즉, X의 길이만큼 단위행렬을 제작한 행렬을 1열로 다시 변환 N * 1 단위 행렬 제작\n",
    "        result = np.concatenate([X,ones],axis=1) # np.concatenate([배열A,배열B,..], axis = n) : 배열을 합쳐서 행렬로 정의 해주는 함수\n",
    "        # n = 0 인 경우 아래로 연결, n = 1 인 경우 좌에서 -> 우측으로 연결\n",
    "        # -> 즉, 위에서 만든 N * 1 단위행렬을 X 행렬에 우측에다가 합침\n",
    "        return result\n",
    "    \n",
    "    def Fit(self,X,Y,intercept_add=False): # 교육함수로 Train 데이터와 intercept Option의 bool 값을 가져와 교육\n",
    "        if(intercept_add == True): # interceppt 사용시\n",
    "            new_X = self.InterceptAdd(X) # X 데이터 행렬을 intercept_add 함수로 재정의\n",
    "            self.coef = np.linalg.inv(new_X.transpose()@new_X)@new_X.transpose()@Y # w 값 계산\n",
    "            return self.coef\n",
    "        else:\n",
    "            self.coef = np.linalg.inv(X.transpose()@X)@X.transpose()@Y # w 값 계산\n",
    "            return self.coef\n",
    "        \n",
    "    def Predict(self,X,intercept_add=False): # 예측 함수로 Test 데이터와 intercept Option의 bool 값을 가져와 에측 값 반환\n",
    "        if(intercept_add==True): # interceppt 사용시\n",
    "            new_X = self.InterceptAdd(X)\n",
    "            predict_value = round(new_X@self.coef) # w 값 계산 하였으니 예측값 행렬 생성\n",
    "            return predict_value\n",
    "        else:\n",
    "            predict_value = round(X@self.coef)\n",
    "            return predict_value\n",
    "\n",
    "class METRIX: # MSE와 MAPE 값을 구하는 class\n",
    "    def __init__(self): #\n",
    "        self.mse_result=0\n",
    "        self.mape_result=0\n",
    "        \n",
    "    def Mse(self,true_y,pred_y):\n",
    "        residual = true_y - pred_y # 실제값과 예측값의 차이인 편차를 계산\n",
    "        square_residual = residual*residual # 편차의 제곱을 계산\n",
    "        self.mse_result =  np.mean(square_residual) # np.mean : 지정된 축을 따라 산술 평균의 배열을 반환 (생략,axis=0)\n",
    "        return self.mse_result\n",
    "        \n",
    "    def Mape(self,true_y,pred_y):\n",
    "        residual = true_y - pred_y # 실제값과 예측값의 차이인 편차를 계산\n",
    "        temp = np.abs(residual)/np.abs(true_y)*100 \n",
    "        # 편차의 합을 실제값으로 나누고 비율 계산을 위해 *100\n",
    "        # np.abs : 절댓값으로 계산\n",
    "        self.mape_result = np.mean(temp)\n",
    "        return self.mape_result\n",
    "\n",
    "model = MLR()\n",
    "model.Fit(x_train_array, y_train_array)\n",
    "y_predict = model.Predict(x_test_array)\n",
    "test = METRIX()\n",
    "print(\"MSE : {:.2f}\".format(test.Mse(y_test_array, y_predict)))\n",
    "print(\"MAPE : {:.2f}%\".format(test.Mape(y_test_array, y_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
